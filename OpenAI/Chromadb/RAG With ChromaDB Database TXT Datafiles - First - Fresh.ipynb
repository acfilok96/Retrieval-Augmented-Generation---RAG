{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip\n",
        "!unzip -q new_articles.zip -d new_articles"
      ],
      "metadata": {
        "id": "tz-cQPbqg8iy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LangChain multi-doc retriever with ChromaDB**"
      ],
      "metadata": {
        "id": "Gf3mQKnsaDoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Files\n",
        "\n",
        "ChromaDB\n",
        "\n",
        "Source info\n",
        "\n",
        "gpt-3.5-turbo"
      ],
      "metadata": {
        "id": "0C3VqWb9aG0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting up LangChain"
      ],
      "metadata": {
        "id": "U1nG9DIpaNrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain openai chromadb tiktoken langchain-openai\n",
        "# !pip install -q --upgrade langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wt8ynQMa6_M",
        "outputId": "7bd2bd30-5abc-420a-a19d-68887a2f537b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.0/509.0 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "57w-QDTsMFyf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "YrnZnt3naaDT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load multiple and process documents"
      ],
      "metadata": {
        "id": "LLlrTgOubCnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process the text files\n",
        "# loader = TextLoader(\"file_name.txt\")\n",
        "\n",
        "loader = DirectoryLoader(\"./new_articles/\", glob = \"./*.txt\", loader_cls = TextLoader)\n",
        "\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "9DQNsBoHa5KW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting the text into\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
        "\n",
        "texts = text_splitter.split_documents(documents)\n",
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-iMl5_nbq5k",
        "outputId": "53dde337-2adf-4405-f985-11e304d67348"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "233"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh77q9IacAcb",
        "outputId": "2a3bf25a-9db9-4211-9c0d-345091c0ce18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='Over the last half-decade, numerous Indian venture firms have shifted their attention to early-stage investments. Despite this increased focus, the market continues to depend on international investors to support mid- and growth-stage deals, highlighting the need for further growth in India’s venture capital ecosystem. “We have high performing mutual funds and PEs. We hope that more of these firms will launch dedicated funds for Indian startups,” he said.\\n\\nHalf of the capital in the new fund for 3one4 has come from Indian investors, another aspect that differentiates the firm from many of its peers. All the systemically important Indian banks, and the top five local banks by market cap overall have invested in the new fund. Eight of the top 10 mutual fund operators are also LPs in the new fund, said Pai. “We are also proud to have leading global endowments, sovereigns and insurance companies as LPs,” he said.', metadata={'source': 'new_articles/05-07-3one4-capital-driven-by-contrarian-bets-raises-200-million-new-fund.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create Database"
      ],
      "metadata": {
        "id": "KnwpAYNYcE3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store te texts\n",
        "# Supplying a persist directory will store the embeddings on disk\n",
        "\n",
        "persist_directory = \"db\"\n",
        "\n",
        "# here we are using OpenAI embeddings but in future swap out to local embeddings\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb = Chroma.from_documents(documents = texts,\n",
        "                                 embedding = embedding,\n",
        "                                 persist_directory = persist_directory)"
      ],
      "metadata": {
        "id": "4OGqRFrWcBSb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# persiste the db to disk\n",
        "\n",
        "vectordb.persist()\n",
        "vectordb = True"
      ],
      "metadata": {
        "id": "JCGL-GpUcBO0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can load the persisted databases from disk, and use it an normal\n",
        "vectordb = Chroma(persist_directory = persist_directory,\n",
        "                  embedding_function = embedding)"
      ],
      "metadata": {
        "id": "PjCucg08cBNd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make a retriever"
      ],
      "metadata": {
        "id": "pJ1aISDZdQqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "AI-byfmfcBMC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = retriever.get_relevant_documents(\"How much money did Pando raise ?\")"
      ],
      "metadata": {
        "id": "2BnL9HTpcBKQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfqbNBu9cBIo",
        "outputId": "55624188-dbeb-4961-eb57-feb4a9099412"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(search_kwargs = {\"k\" : 2})"
      ],
      "metadata": {
        "id": "m33HmbAIcBHI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tiaN0KhOcBF3",
        "outputId": "874f88f1-5a1d-49d2-b5bc-f0eb368d2694"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'similarity'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.search_kwargs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgreuIQCdp6r",
        "outputId": "c950c690-c88f-45c7-c3d9-db5bc8726e39"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'k': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Make a chain"
      ],
      "metadata": {
        "id": "u3XmUaM5eDj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chain to answer questions\n",
        "qa_chain = RetrievalQA.from_chain_type(llm = OpenAI(),\n",
        "                                       chain_type = \"stuff\",\n",
        "                                       retriever = retriever,\n",
        "                                       return_source_documents = True)"
      ],
      "metadata": {
        "id": "cUQZotladp3O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cite sources\n",
        "\n",
        "def process_llm_response(llm_response):\n",
        "  print(llm_response['result'])\n",
        "  print(\"\\n\\nSource:\")\n",
        "  for source in llm_response[\"source_documents\"]:\n",
        "    print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "vsfFvcMWdp1S"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full example\n",
        "query = \"How much did photo raise ?\"\n",
        "llm_response = qa_chain.invoke(query)\n",
        "llm_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnQzzbj3dpzq",
        "outputId": "ad6a5a71-9f2b-4bac-f44e-0b1f5c468625"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How much did photo raise ?',\n",
              " 'result': '\\nI\\'m sorry, I don\\'t have enough information to answer that question. The context provided does not mention a company or product named \"photo.\"',\n",
              " 'source_documents': [Document(page_content='Etc.\\n\\nAmazon rolled out a Matter update for Alexa that includes support for Thread, setup on iOS, and a new version of its Works with Alexa program.\\n\\nand a new version of its Works with Alexa program. Match Group posted a Q1 earnings miss with revenue down by 1% YoY to $787 million and paying users down 3% to 15.9 million. The company, however, said it’s “very possible” the recent Apple-Epic court decision could result in App Store fee relief.\\n\\nMedtech startup Healthy.io, which provides urine analysis through a mobile app, is laying off a third of its staff, or around 70 people. The company had just raised $50 million in Series D funding.\\n\\nThe company had just raised $50 million in Series D funding. Airbnb announced Rooms, a feature that focuses on the ability to book single rooms averaging $67 per night as users complain about excessive fees, onerous checkout procedures and rising Airbnb prices.', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'}),\n",
              "  Document(page_content='but hasn’t shared exactly what that plan may involve. Last year, the company began shifting its focus away from public audio to private rooms but it’s not clear there’s much demand for audio social networking in the post-pandemic market. Once-hot viral app Poparazzi shuts down and returns remaining funds to investors. The app had let friends tag others to build out their social profiles of real moments, not polished images, but had been on the decline, with only a few thousand MAUs down from a height of 4 million MAUs previously.\\n\\nA Twitter bug saw users able to regain their blue Verification checks just by editing their bio. Shortly afterward, the Twitter desktop website began randomly logging out users. Later in the week, the mobile website was also down.', metadata={'source': 'new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGCwy2lKdpx1",
        "outputId": "f3a5ffda-fcf8-4d0d-e0f2-90e6df2a3b21"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I'm sorry, I don't have enough information to answer that question. The context provided does not mention a company or product named \"photo.\"\n",
            "\n",
            "\n",
            "Source:\n",
            "new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n",
            "new_articles/05-06-this-week-in-apps-apple-and-google-team-up-on-trackers-google-i-o-preview-apps-hit-newfronts.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain.retriever.search_type, qa_chain.retriever.vectorstore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juQHxsGCdpv2",
        "outputId": "a66c52d3-a9cb-43ec-81f9-f175c612331b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('similarity',\n",
              " <langchain_community.vectorstores.chroma.Chroma at 0x7a0483d01fc0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chat prompts"
      ],
      "metadata": {
        "id": "RLVpYpeXgeIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKB9UF3Ugdsr",
        "outputId": "e0397399-3115-4e5e-9e42-cbe8a1abcf2d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "{context}\n",
            "\n",
            "Question: {question}\n",
            "Helpful Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa_chain.combine_documents_chain.llm_chain.prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mn2FJCyxgsjS",
        "outputId": "b0ffb26b-f63f-44fa-ebfb-5709c1d32d1f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "{context}\n",
            "\n",
            "Question: {question}\n",
            "Helpful Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deleting the database"
      ],
      "metadata": {
        "id": "u3G-N-TCf0WR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r db.zip ./db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpnHeBgn_F2D",
        "outputId": "932e6022-2ae6-49d8-ae4e-671665ade106"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: db/ (stored 0%)\n",
            "  adding: db/chroma.sqlite3 (deflated 41%)\n",
            "  adding: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/ (stored 0%)\n",
            "  adding: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/length.bin (deflated 12%)\n",
            "  adding: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/data_level0.bin (deflated 100%)\n",
            "  adding: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/link_lists.bin (stored 0%)\n",
            "  adding: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/header.bin (deflated 61%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To clean up, you can delete the collection\n",
        "vectordb.delete_collection()\n",
        "vectordb.persist()\n",
        "\n",
        "# delete the directory\n",
        "!rm -rf db/"
      ],
      "metadata": {
        "id": "HUezrWl1_JWU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Starting again loading the db"
      ],
      "metadata": {
        "id": "G3PlZIXY_btb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "restart the runtime"
      ],
      "metadata": {
        "id": "Ri_3Mmbb_fOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/db.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD8mpGBFfz2P",
        "outputId": "7a7742c7-22d6-4cf4-89c9-52672de2bdc2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/db.zip\n",
            "   creating: db/\n",
            "  inflating: db/chroma.sqlite3       \n",
            "   creating: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/\n",
            "  inflating: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/length.bin  \n",
            "  inflating: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/data_level0.bin  \n",
            " extracting: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/link_lists.bin  \n",
            "  inflating: db/67f3c5bf-2c2a-4d51-9bff-89cdd53ab650/header.bin  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "persist_directory = \"/content/db\"\n",
        "embedding = OpenAIEmbeddings()\n",
        "\n",
        "vectordb2 = Chroma(persist_directory = persist_directory,\n",
        "                   embedding_function = embedding)\n",
        "\n",
        "retriever = vectordb2.as_retriever(search_kwargs = {\"k\" : 2})"
      ],
      "metadata": {
        "id": "5J_94Pokfzv3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up turbo llm\n",
        "\n",
        "turbo_llm = ChatOpenAI(\n",
        "    temperature = 0.0,\n",
        "    model_name = \"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "id": "Xwd_1R1BfzuB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chain to answer questions\n",
        "# from langchain.llms import OpenAI\n",
        "qa_chain = RetrievalQA.from_chain_type(llm = OpenAI(),\n",
        "                                       chain_type = \"stuff\",\n",
        "                                       retriever = retriever,\n",
        "                                       return_source_documents = True)"
      ],
      "metadata": {
        "id": "8bsDQTtgfzsb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cite sources\n",
        "def process_llm_response(llm_response):\n",
        "  print(llm_response['result'])\n",
        "  print(\"\\n\\nSource:\")\n",
        "  for source in llm_response[\"source_documents\"]:\n",
        "    print(source.metadata['source'])"
      ],
      "metadata": {
        "id": "_I1U17QtAejl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full example\n",
        "query = \"How much did Pando raise ?\"\n",
        "llm_response = qa_chain.invoke(query)\n",
        "llm_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWP4XntRAegY",
        "outputId": "8f759533-2698-46c1-8fb3-fa6ed67c76fb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'How much did Pando raise ?',\n",
              " 'result': ' Pando raised $30 million in the Series B round, bringing its total raised to $45 million.',\n",
              " 'source_documents': [Document(page_content='Signaling that investments in the supply chain sector remain robust, Pando, a startup developing fulfillment management technologies, today announced that it raised $30 million in a Series B round, bringing its total raised to $45 million.\\n\\nIron Pillar and Uncorrelated Ventures led the round, with participation from existing investors Nexus Venture Partners, Chiratae Ventures and Next47. CEO and founder Nitin Jayakrishnan says that the new capital will be put toward expanding Pando’s global sales, marketing and delivery capabilities.\\n\\n“We will not expand into new industries or adjacent product areas,” he told TechCrunch in an email interview. “Great talent is the foundation of the business — we will continue to augment our teams at all levels of the organization. Pando is also open to exploring strategic partnerships and acquisitions with this round of funding.”', metadata={'source': 'new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'}),\n",
              "  Document(page_content='The result of those major disruptions? The digital logistics market is estimated to climb to $46.5 billion by 2025, per Markets and Markets — up from $17.4 billion in 2019. Crunchbase reports that investors poured more than $7 billion in seed through growth-stage rounds globally for supply chain-focused startups from January to October 2022, nearly eclipsing 2021’s record-setting levels.\\n\\n“Pando has a strong balance sheet and profit and loss statement, with an eye on profitable growth,” Jayakrishnan said. “We’re are scaling operations in North America, Europe and India with marquee customer wins and a network of strong partners … Pando is well-positioned to ride this growth wave, and drive supply chain agility for the 2030 economy.”', metadata={'source': 'new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt'})]}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "process_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yurCkZkTAefH",
        "outputId": "c4c48317-cab9-46d0-9f2e-8b9b1cbcbddf"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pando raised $30 million in the Series B round, bringing its total raised to $45 million.\n",
            "\n",
            "\n",
            "Source:\n",
            "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n",
            "new_articles/05-03-ai-powered-supply-chain-startup-pando-lands-30m-investment.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "                                -: END :-"
      ],
      "metadata": {
        "id": "RkQYhn-jG5gP"
      }
    }
  ]
}